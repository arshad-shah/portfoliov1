<!doctype html>
<!-- Author : Arshad shah -->
<!--Start of page-->
<html>
  <!--start of head-->
  <head>
    <meta charset="utf-8">
    <meta name="description" content="Artificial intelligence is the new frontier for humans, Which we can achieve without space rockets.">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <!--favicon for browser tab-->
    <link rel='icon' href='Assets/images/favicon.png' type='image/x-icon'/ >

    <title> Dangers of A I </title>
    <!--normal handmade style sheet for website design-->
    <link rel="stylesheet" href="Assets/css/style.css">

    <!--imported stylesheet for icons-->
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css">

    <!--imported style sheet for the font styling of the web page-->
    <link href="https://fonts.googleapis.com/css?family=Ruda&display=swap" rel="stylesheet">

    <!--imported style sheet for the back to top button styling of the web page-->
    <link href="https://netdna.bootstrapcdn.com/font-awesome/3.2.1/css/font-awesome.css" rel="stylesheet">

    <!--javascript for menu toggle-->
    <script src="Assets/scripts/menu_design.js"></script>

    <!--back to top script-->
    <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.2.1/jquery.min.js"></script>
    <script src="Assets/scripts/back_to_top.js"></script>

  </head>
  <!--end of Head section-->

  <!--start of body section-->
  <body>
    <!--back to top button-->
    <button onclick="topFunction()" id="myBtn" title="Go to top">&#11165;</button>

    <!--wrapper-->
    <div class="wrapper">

      <!--start of header-->
      <header>
        <aside class="logo">
            <img src="Assets/images/logo.png" alt="website logo">
        </aside>
            <h1>Artificial Intelligence</h1>
      </header>
      <!--end of Header-->

    <!--menu toggle-->
    <!-- Top Navigation Menu -->
      <div class="topnav" id="myTopnav">
        <a href="index.html" class="active"><i class="fa fa-home"></i>Home</a>
          <a href="benefits.html">Benefits</a>
          <a href="dangers.html">Dangers </a>
          <a href="development.html"> Development</a>
          <a href="contact.html"> <i class="fa fa-envelope"></i> Contact Us</a>
          <a href="https://arshad-shah.github.io"> Go back to main site</a>
        <!-- "Hamburger menu" / "Bar icon" to toggle the navigation links -->
        <a class="icon" onclick="myFunction()"> <i class="fa fa-bars"></i> </a>
      </div>
    <!--end of menu toggle-->

    <!--start main page content-->
    <section class="main">
      <article class="mainart">
        <h1>DANGERS OF AI</h1>
        <aside class="aiaware">
          <img src="Assets/images/danger.png" alt="singularity of ai">
          <h6>A Daigram illustrating singularity</h6>
          <h6>Taken from <a href="http://highlighthollywood.com/2018/11/hbo-documentary-the-truth-about-killer-robots-debuts-this-month/"> >>Highlighthollywood<< </a> </h6>
        </aside>

        <p>
          <h1> Artificial Intelligence has both benefits and Dangers associated with it, we will talk about its Dangers here</h1>
          The world is split on the benefits of AI and the Dangers of AI.
          <br>
          but the main theory in a way that is going around the world is called the <strong> <b> Existential Risk </b> </strong>
          <br>
          <br>
          Existential risk from artificial general intelligence is the hypothesis that substantial progress in artificial general intelligence (AGI) could someday result in human extinction or some other unrecoverable global catastrophe.
          <br>
          <br>
          It is argued that the human species currently dominates other species because the human brain has some distinctive capabilities that other animals lack.
          <br>
          If AI surpasses humanity in general intelligence and becomes "superintelligent", then this new superintelligence could become powerful and difficult to control.
          <br>
          Just as the fate of the mountain gorilla depends on human goodwill, so might the fate of humanity depend on the actions of a future machine superintelligence.
          <br>
          <br>

          The likelihood of this type of scenario is widely debated, and hinges in part on differing scenarios for future progress in computer science.
          Once the exclusive domain of science fiction,
          <br>
          concerns about superintelligence started to become mainstream in the 2010s,
          and were popularized by public figures such as Stephen Hawking, Bill Gates, and Elon Musk.

        </p>
      </article>

      <aside class="statpic">
        <img src="Assets/images/spy.png" alt="danger gif">
        <h6>A Daigram illustrating AI in surveillance</h6>
        <h6>Taken from <a href="https://futurism.com/ai-cameras-use"> >>Futurism<< </a> </h6>
      </aside>

      <article class="subart">
        <p>
          <div class="header">
            <h1><q> <i> AI doesn't have to be evil to destroy humanity â€“ if AI has a goal and humanity just happens to be in the way, it will destroy humanity as a matter of course without even thinking about it, no hard feelings.</i></q>
              <br> -- Elon Musk, Technology Entrepreneur, and Investor --
              </h1>
          </div>

          <br>
          The above qoute explains the iminant danger to life from AI not because it Hates humans but because it has a job to do.
          <br>
          This will happen once we get to superintelligence level because AI cannot be taught to love. if that happens then humanity can avoid this situation but in reality it is impossible to do,
          <br>
          The reason for that being that humans dont know how our brain work in the first place. so it is impossible to replicate that.
          <br>
          <aside class="dangervid">
            <iframe width="560" height="315" src="https://www.youtube-nocookie.com/embed/XVS4Iw8zc88?start=10" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
            <h6>A talk on "what makes ai dangerous"</h6>
            <h6>Taken from <a href="https://www.youtube.com/watch?v=XVS4Iw8zc88"> >>Youtube<< </a> </h6>
          </aside>
          <br>
          This video shows the reasons that AI may be dangerous.
          <div class="fate">
            <img src="Assets/images/meta-chart.png" alt="picture of the fate of humanity">
          </div>
          <br>
          This chart shows the fear that developers of the algorithms have regarding AI.
          <br>
          <br>
          where the singularity and independent decision making are the worst of there fears,
          because if AI becomes a singularity in other words smarter then us then the consequences will be catastrophic.
          <br>
          The reason being that as long as it is less intelligent then we are we can tackle with it but if it overtakes us in intelligence then
          <br>
          it becomes somewhat impossible to do so as if we take the chimpanzee as an example we humans can take down the chimpanzee but the chimpanzee cannot do that as easily as we can anicipate its next move very early.
          <br>
          <br>
          Independent decision making is second on the list as if algorithms make independent decisions it takes out the ability to control from humans,
          And creates unlimited possiblities for the decision that the algorithm makes.
          <br>
          therefore going towards a singularity.
          <br>
          third is the definition of fairness in our society, Fairness is something that we humans use to define the good or the bad.
          <br>
          if an AI takes it upon itself to define fairness it causes problems because it can define fairness to its own benefit or rather understanding and therefore if it considers something dangerous it may mark it bad,
          <br>
          where that thing may be beneficial to humans.
          <br>
          <br>
          the last thing on the list is automation of jobs, Now this is up to debate but generally it is considered that the much simple hand work like car manufacture and cloth manufacture is taken from the humans with narrow AI.
          <br>
          we may therefore lose all of our jobs to general intelligence.
          <br>
          in some cases it is tru but in others it is false.
          <br>
          e.g.
          <br>
          the welding in a car factory is done by AI but in order to keep everything move smootly technician are needed to look after the machines.

        </p>
      </article>


    </section>
    <!--end of main page content-->

    <!--footer of the page-->
    <footer> <h4>&copy; 2019 by  <strong> Arshad Shah </strong></h4> <h6>shaharshad57@gmail.com</h6> </footer>
    </div>

  </body>
  <!--end of body section-->
</html>
<!--end of main page-->
